{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "DS_Bitácora_29_Clustering.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUGASKQBEW1W"
      },
      "source": [
        "# Clustering\n",
        "\n",
        "## 1. K-means y DBSCAN\n",
        "\n",
        "En esta primera parte, vamos a trabajar con los métodos K-means y DBSCAN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBFDbKSwEW1b"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "sns.set()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qllrZfQuEW1c"
      },
      "source": [
        "Para empezar, vamos a generarnos una serie de datasets sintéticos con las funciones que ya vienen incorporadas en Scikit-learn. Notemos que estos datos vienen con una etiqueta asociada donde nos indica a qué cluster pertenecen. La idea será utilizar los métodos de clustering estudiados para poder identificar los clusters sin conocer esta etiqueta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bA-MdL_pEW1g"
      },
      "source": [
        "from sklearn.datasets import make_blobs, make_moons\n",
        "\n",
        "X1, y1 = make_blobs(n_samples=1000, centers=4, cluster_std=0.5, n_features=2, random_state=0)\n",
        "X2, y2 = make_blobs(n_samples=1000, centers=4, cluster_std=1, n_features=2, random_state=0)\n",
        "X3, y3 = make_moons(n_samples=1000, noise=.05, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imE64cXqEW1i"
      },
      "source": [
        "Grafiquemos los datasets para ver las diferencias entre cada uno."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIYIoic2EW1j"
      },
      "source": [
        "sns.scatterplot(x = X1[:,0], y = X1[:,1], hue = y1)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xP0Lq5QoEW1k"
      },
      "source": [
        "sns.scatterplot(x = X2[:,0], y = X2[:,1], hue = y2)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msWTq9GjEW1l"
      },
      "source": [
        "sns.scatterplot(x = X3[:,0], y = X3[:,1], hue = y3)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsghZgnlEW1l"
      },
      "source": [
        "### 1.1 K-means\n",
        "\n",
        "Scikit-Learn tiene una implementación de K-means.\n",
        "\n",
        "1. Lee la documentación.\n",
        "\n",
        "2. Define los 3 modelos para los distintos datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvD34lAwEW1m"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Especificamos el numero adecuado de clusters en cada caso\n",
        "kmeans_1 = KMeans(n_clusters=COMPLETAR, random_state=0)\n",
        "kmeans_2 = KMeans(COMPLETAR, random_state=0)\n",
        "kmeans_3 = KMeans(COMPLETAR, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gliRf861EW1n"
      },
      "source": [
        "3. Entrena los modelos con los datos, recuerda que NO hay que pasarles las etiquetas, solo los atributos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUjI9kvdEW1o"
      },
      "source": [
        "kmeans_1.COMPLETAR\n",
        "kmeans_2.COMPLETAR\n",
        "kmeans_3.COMPLETAR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpQn23MGEW1o"
      },
      "source": [
        "Luego de entrenar los modelos, podemos consultar las etiquetas que se le asignó a cada instancia y el lugar de los centroides."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcWY4beQEW1p"
      },
      "source": [
        "etiquetas_1 = kmeans_1.labels_\n",
        "print(etiquetas_1.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLrCviZBEW1p"
      },
      "source": [
        "centros_1 = kmeans_1.cluster_centers_\n",
        "print(centros_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jernD5KEW1q"
      },
      "source": [
        "etiquetas_2 = kmeans_2.labels_\n",
        "centros_2 = kmeans_2.cluster_centers_\n",
        "etiquetas_3 = kmeans_3.labels_\n",
        "centros_3 = kmeans_3.cluster_centers_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSCnjfD_EW1r"
      },
      "source": [
        "4.  Ploteamos los resultados para todos los datasets. ¿Les parece que la separación fue adecuada?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrwAl6QHEW1r"
      },
      "source": [
        "sns.scatterplot(X1[:, 0], X1[:, -1], hue = etiquetas_1)\n",
        "sns.scatterplot(centros_1[:, 0], centros_1[:, 1],color='black', marker=\"+\", s=1000)\n",
        "plt.title('Data points and cluster centroids')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssD1uAjuEW1s"
      },
      "source": [
        "sns.scatterplot(X2[:, 0], X2[:, -1], hue = etiquetas_2)\n",
        "sns.scatterplot(centros_2[:, 0], centros_2[:, 1],color='black', marker=\"+\", s=1000)\n",
        "plt.title('Data points and cluster centroids')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwBFYNoMEW1t"
      },
      "source": [
        "sns.scatterplot(X3[:, 0], X3[:, -1], hue = etiquetas_3)\n",
        "sns.scatterplot(centros_3[:, 0], centros_3[:, 1],color='black', marker=\"+\", s=1000)\n",
        "plt.title('Data points and cluster centroids')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSYAOXXeEW1u"
      },
      "source": [
        "Para ver el acuerdo que hubo entre los clusters determinados por el algoritmos de clustering y los generados originalmente, podemos usar una matriz de confusión. Notemos que no sabemos si los nombres de los clusters se corresponden entre sí, el cluster 0 en los datos originales podría ser el cluster 1 en los calculados con k-means."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9O7b9bVEW1u"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y1, etiquetas_1)\n",
        "df_cm = pd.DataFrame(cm, index = [i for i in ['Original_0','Original_1','Original_2','Original_3']],\n",
        "                  columns = [i for i in ['Pred_0','Pred_1','Pred_2','Pred_3']])\n",
        "plt.figure(figsize = (10,7))\n",
        "sns.heatmap(df_cm, annot=True, fmt=\"d\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnIcSQi1EW1x"
      },
      "source": [
        "5. Repite el ploteo de la matriz de confusión para los otros datasets. ¿Se te ocurre alguna manera de cuantificar el acuerdo entre ambos sets de etiquetas (el original y el obtenido por clustering)?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yPc2WJwEW1z"
      },
      "source": [
        "cm = confusion_matrix(COMPLETAR)\n",
        "df_cm = pd.DataFrame(COMPLETAR)\n",
        "plt.figure(figsize = (10,7))\n",
        "sns.heatmap(df_cm, annot=True, fmt=\"d\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Vzv4nBXEW10"
      },
      "source": [
        "cm = confusion_matrix(COMPLETAR)\n",
        "df_cm = pd.DataFrame(cm, index = [i for i in ['Original_0','Original_1']],\n",
        "                  columns = [i for i in ['Pred_0','Pred_1']])\n",
        "plt.figure(figsize = (10,7))\n",
        "sns.heatmap(df_cm, annot=True, fmt=\"d\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlFzfbNcEW10"
      },
      "source": [
        "6. Prueba qué sucede si no elige correctamente el número de clusters. ¿Se le ocurre cómo puede usar las matrices de confusión para darse cuenta que no eligió correctamente ese número?\n",
        "\n",
        "### 1.2 DBSCAN\n",
        "\n",
        "1. Lee la documentación.\n",
        "2. Define los 3 modelos para los distintos datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "habWG70eEW11"
      },
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "# En este paso tenemos que definir el epsilon y en min_samples, los parametros del método.\n",
        "db_1 = DBSCAN(eps=0.3, min_samples=10)\n",
        "db_2 = DBSCAN(COMPLETAR)\n",
        "db_3 = DBSCAN(COMPLETAR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_N0TrZkWEW12"
      },
      "source": [
        "3. Entrena los modelos con los distintos datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3oH7OWaEW13"
      },
      "source": [
        "db_1.COMPLETAR\n",
        "db_2.COMPLETAR\n",
        "db_3.COMPLETAR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09t8F5ZJEW13"
      },
      "source": [
        "Podemos consultar las etiquetas asignadas luego de entrenar en la variable `labels_`. Notemos que cuando el label sea igual a '-1' quiere decir que esa instancia fue considerada ruido. \n",
        "\n",
        "4. Teniendo en cuenta esto, podemos obtener el numero de clusters y el numero de instancias consideradas ruido de la siguiente forma (solo lo hacemos para el primer dataset):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPmlfrOwEW14"
      },
      "source": [
        "# Consultamos las etiquetas\n",
        "labels_1 = db_1.labels_\n",
        "\n",
        "# Number of clusters in labels, ignoring noise if present.\n",
        "n_clusters_1 = len(set(labels_1)) - (1 if -1 in labels_1 else 0)\n",
        "n_noise_1 = list(labels_1).count(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ckRwS4lEW15"
      },
      "source": [
        "print('Estimated number of clusters: %d' % n_clusters_1)\n",
        "print('Estimated number of noise points: %d' % n_noise_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90xWqK6bEW15"
      },
      "source": [
        "Les damos ya definida una función que plotea los resultados de manera tal que colorea con distintos colores los distintos clusters, en gris los datos que se consideran Noise y ademas en tamaño mas grande las instancias que son CORES. No hace falta que cambien nada de esta función."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuzhJUFLEW16"
      },
      "source": [
        "# Funcion para plotear, NO CAMBIAR NADA\n",
        "def plot_DBSCAN(X1,labels_1,db_1,n_clusters_1):\n",
        "    # Armamos una mascara, con unos en los datos que son CORES.\n",
        "    core_samples_mask_1 = np.zeros_like(db_1.labels_, dtype=bool)\n",
        "    core_samples_mask_1[db_1.core_sample_indices_] = True\n",
        "    # Plot result\n",
        "\n",
        "    # Black removed and is used for noise instead.\n",
        "    unique_labels = set(labels_1)\n",
        "    colors = [plt.cm.Spectral(each)\n",
        "              for each in np.linspace(0, 1, len(unique_labels))]\n",
        "    for k, col in zip(unique_labels, colors):\n",
        "        if k == -1:\n",
        "            # Black used for noise.\n",
        "            col = [0, 0, 0, 1]\n",
        "\n",
        "        class_member_mask = (labels_1 == k)\n",
        "\n",
        "        xy = X1[class_member_mask & core_samples_mask_1]\n",
        "        plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
        "                 markeredgecolor='k', markersize=14)\n",
        "\n",
        "        xy = X1[class_member_mask & ~core_samples_mask_1]\n",
        "        plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
        "                 markeredgecolor='k', markersize=6)\n",
        "    plt.title('Estimated number of clusters: %d' % n_clusters_1)\n",
        "    plt.show()\n",
        "    return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSNHKx_BEW17"
      },
      "source": [
        "5. Ploteamos el resultado para el primer caso. ¿Te parece adecuado el resultado? Prueba qué pasa si modifica los parámetros de epsilon y min_dist."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bHfWULdEW19"
      },
      "source": [
        "plot_DBSCAN(X1,labels_1,db_1,n_clusters_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeWaTfEyEW19"
      },
      "source": [
        "6. Repetimos el paso 5 para los otros 2 datasets, nota que debe calcular `labels_2`, `core_samples_mask_2`, etc... Recomendación: vuelva a copiar todo el codigo en las siguientes celdas en lugar de modificar el que ya tiene escrito para el dataset 1. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pPjRHyLEW1-"
      },
      "source": [
        "COMPLETAR\n",
        "\n",
        "plot_DBSCAN(X2,labels_2,db_2,n_clusters_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1dUKO_UEW1-"
      },
      "source": [
        "COMPLETAR\n",
        "\n",
        "plot_DBSCAN(X2,labels_2,db_2,n_clusters_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efeaGAiHEW1_"
      },
      "source": [
        "7. Ajustar los parametros `epsilon` y `min_dist` para lograr un resultado lo más parecido al dataset original posible.\n",
        "\n",
        "8. A partir de los resultados obtenidos, reflexione sobre las fortalezas y debilidades de cada uno de los métodos.\n",
        "\n",
        "\n",
        "## 2. ¡A probar con un dataset!\n",
        "\n",
        "Elige un dataset que te interese y aplica las técnicas vistas. ¿Qué esperas obtener?¿Qué obtienes? Por ejemplo, puedes aplicarlo sobre el dataset Iris (¿qué ocurre si usas `n_clusters=2` y `n_clusters=3` en k-means?), o el dataset del proyecto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4g8JPt8EW2C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rt-Z_OKREW2C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lfCWs9xEW2D"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}