{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DS_Bitácora_23_Regresion_Avanzada.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XR4utuECTChT"
      },
      "source": [
        "# Regresión Lineal - Recargado\n",
        "\n",
        "En este notebook pondrás en práctiva la aplicación de modelos de regresión lineal a problemas no lineales. También incroporarás la técnica de regularización para evitar el overfitting, un problema común en este tipo de enfoques.\n",
        "\n",
        "\n",
        "## 1. Regresión No-Lineal\n",
        "\n",
        "Vamos a comenzar, como siempre hacemos en estos temas, con un ejemplo controlado. Supongamos que tenenos un dataset con dos atributos, $x$ e $y$, y la relación entre ellos es $y = -2x^4+3x^2+1$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ak7NXFgFMSMG"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENFalLaRV5OG"
      },
      "source": [
        "La siguiente celda genera nuestro dataset sintético. Le sumamos ruido para simular una situación más realista."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPBM6sutNEzt"
      },
      "source": [
        "n = 300\n",
        "x = np.linspace(-1,1,n)\n",
        "y_real = -1.5*x**4+3*x**2+1\n",
        "y = y_real + 0.1*np.random.randn(n)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gttgRwjqYlQI"
      },
      "source": [
        "Graficamos la muestra y la curva teórica."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBg7rf3yMSX-"
      },
      "source": [
        "plt.scatter(x,y, s = 2, label = 'Datos')\n",
        "plt.plot(x, y_real, '--',label ='Curva Teórica', c = 'r')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezbqvPBTZFzT"
      },
      "source": [
        "Vamos a entrenar un modelo de Regresión Lineal, al que llamaremos `reg_1`. Primero, vamos a definir nuestro dataset `X` (notar la diferencia con la variable `x`)- Luego, hacer un `train_test_split`, y entrenar la regresión lineal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6Cguy4mXdHg"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = x.reshape(-1,1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2fQJBHjXUne"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "reg_1 = LinearRegression()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3glwgremXfEe"
      },
      "source": [
        "reg_1.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-GuyJxYs4c4"
      },
      "source": [
        "y_train_pred_1 = reg_1.predict(X_train)\n",
        "y_test_pred_1 = reg_1.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJfyAZJGZh6G"
      },
      "source": [
        "Graficamos la regresión obtenida."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUkJ1AsRMScC"
      },
      "source": [
        "plt.figure(figsize = (8,4))\n",
        "plt.scatter(x,y, s = 2, label = 'Datos')\n",
        "plt.plot(x, y_real, '--',label ='Curva Teórica', c = 'r')\n",
        "plt.scatter(X_test,y_test_pred_1,label ='Regresion Lineal (Test)', c = 'g')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vntYksMs4c5"
      },
      "source": [
        "Ya en el gráfico podemos ver que la regresión obtenida es un modelo malo, ya que no captura correctamente la relación entre $x$ e $y$, salvo por, prácticamente, su valor medio.\n",
        "\n",
        "De todas formas, calculamos el error RMSE, hacemos un histograma de los errores en el conjunto de Train y Test, y una curva `y` vs `y_pred`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fzu8Vreus4c5"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred_1))\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred_1))\n",
        "print(f'Raíz del error cuadrático medio en Train: {rmse_train}')\n",
        "print(f'Raíz del error cuadrático medio en Test: {rmse_test}')\n",
        "\n",
        "plt.figure(figsize = (8,4))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "sns.distplot(y_train - y_train_pred_1, bins = 20, label = 'train')\n",
        "sns.distplot(y_test - y_test_pred_1, bins = 20, label = 'test')\n",
        "plt.xlabel('errores')\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "ax = plt.subplot(1,2,2)\n",
        "ax.scatter(y_test,y_test_pred_1, s =2)\n",
        "\n",
        "lims = [\n",
        "np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
        "np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes]\n",
        "]\n",
        "\n",
        "ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
        "plt.xlabel('y (test)')\n",
        "plt.ylabel('y_pred (test)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxenjNoOZzKt"
      },
      "source": [
        "Tal cómo sucedió en ejemplo de la bitácora, el modelo parece muy lejos de la realidad. Veamos si lo podemos mejorar.\n",
        "\n",
        "Para facilitar la comprensión del código, vamos a crear una función que nos sirva para evaluar modelos de regresión."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZp6bzm5s4c6"
      },
      "source": [
        "def evaluar_regresion(model,x,y, X_train, X_test, y_train, y_test):\n",
        "    \n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "    \n",
        "    ### CALCULAMOS EL ERROR\n",
        "    rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "    rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "\n",
        "    print(f'Raíz del error cuadrático medio en Train: {rmse_train}')\n",
        "    print(f'Raíz del error cuadrático medio en Test: {rmse_test}')\n",
        "\n",
        "    ### GRAFICAMOS LOS RESULTADOS\n",
        "    plt.figure(figsize = (12,4))\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.scatter(x,y, s = 2, label = 'Datos')\n",
        "    plt.plot(x, y_real, '--',label ='Curva Teórica', c = 'r')\n",
        "    \n",
        "    list1, list2 = zip(*sorted(zip(X_train[:,0], y_train_pred)))\n",
        "    plt.plot(list1, list2,label ='Regresión (train)')\n",
        "    \n",
        "    list1, list2 = zip(*sorted(zip(X_test[:,0], y_test_pred)))\n",
        "    plt.plot(list1, list2,label = 'Regresión (test)')\n",
        "\n",
        "    plt.xlabel('x')\n",
        "    plt.ylabel('y')\n",
        "    plt.legend()\n",
        "\n",
        "\n",
        "    plt.subplot(1,3,2)\n",
        "    sns.distplot(y_train - y_train_pred, bins = 20, label = 'train')\n",
        "    sns.distplot(y_test - y_test_pred, bins = 20, label = 'test')\n",
        "    plt.xlabel('errores')\n",
        "    plt.legend()\n",
        "\n",
        "    ax = plt.subplot(1,3,3)\n",
        "    ax.scatter(y_test,y_test_pred, s =2)\n",
        "\n",
        "    lims = [\n",
        "    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
        "    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes]\n",
        "    ]\n",
        "\n",
        "    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
        "    plt.xlabel('y (test)')\n",
        "    plt.ylabel('y_pred (test)')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ke9jlKXQaCov"
      },
      "source": [
        "### 1.2 Atributos Polinómicos\n",
        "\n",
        "\n",
        "Vamos a agregar al dataset, `X`, nuevos atributos polinómicos: $x^2, x^3$ y $x^4$  y volver a ajustar la regresión lineal.\n",
        "\n",
        "Cada atributo lo vamos a agregar de a uno, y vamos a ver cómo se modifica la regresión. **Presta mucha atención al código**. Al agregar un atributo nuevo, ¿qué ocurría con la regresíon lineal?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyA7fitaL1Bb"
      },
      "source": [
        "for idx,potencia_maxima in enumerate(range(1,6)):\n",
        "    print(f'REGRESIÓN CON ATRIBUTOS POLINÓMICOS NUMERO {idx + 1}')\n",
        "    print(f'Agregamos atributos hasta la potencia x**{potencia_maxima}')\n",
        "    \n",
        "    X = x.reshape(-1,1)\n",
        "    for potencia in range(2,potencia_maxima+1):\n",
        "        X = np.hstack((X,(x**potencia).reshape(-1,1)))\n",
        "    print(f'Los atributos tienen forma: {X.shape}')\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.25, random_state=42)\n",
        "    \n",
        "    ### ENTRENAMOS\n",
        "    reg = LinearRegression()\n",
        "    reg.fit(X_train, y_train)\n",
        "    \n",
        "    \n",
        "    ### COMPLETAR AQUI PARA RESOLVER CHALLENGE\n",
        "    \n",
        "    evaluar_regresion(reg, x,y, X_train, X_test, y_train, y_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85qnFqQkcsPj"
      },
      "source": [
        "Una aclaración sobre el código: es una buena práctica estandarizar los datos (normalizar) antes de entrenar una regresión lineal. No lo hicimos para no saturar (aún más) la explicación.\n",
        "\n",
        "\n",
        "**Para Pensar - Challenge**\n",
        "\n",
        "1. ¿Por que no parecen haber cambios entre el segundo y el tercer gráfico?¿Y entre el cuarto y el quinto?\n",
        "2. Modifica el código de forma tal que imprima los coeficientes (pendientes y ordenada al origen) de cada regresión entrenada.\n",
        "3. Agrega atributos de orden polinómico más alto y observa qué sucede. **Nota:** la modificación que tienes que hacer en el código es mínima. No tengas miedo de probar diferentes órdenes de magnitud.\n",
        "\n",
        "## 2. `PolynomialFeatures`\n",
        "\n",
        "En la práctica, no deberás agregar atributos polinómicos como hicimos en el ejemplo anterior, sino que podrás usar la clase `PolynomialFeatures` de Scikit-Learn. Lee atentamente su documentación y aplícala en el mismo problema de la sección 1. Nosotros te guiamos en los pasos, pero si crees que no lo necesitas, puedes hacerlo en un notebook aparte o borrar las celdas con indicaciones.\n",
        "\n",
        "**Atención:** Recordá que en estos ejercicios conocemos la forma real de los datos (el polinomio) porque los generamos nosotros. En la realidad no lo vas a conocer, por lo que el grado máximo a incoporar es un hiperparámetro.\n",
        "\n",
        "1. Importa la clase `PolynomialFeatures`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHwCkMDss_kh"
      },
      "source": [
        "# COMPLETAR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYTyO32Js4c7"
      },
      "source": [
        "2. Vuelve a definir `X` a partir de `x`, y haz un `train_test_split`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drCc2nT8tq2x"
      },
      "source": [
        "X = # COMPLETAR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gfr5w0wHs4c7"
      },
      "source": [
        "3. Crea un objeto a partir de `PolynomialFeatures` de suficiente `degree` para este problema. Aplícalo sobre `X_train` e `X_test`. Imprime en pantalla el `shape` de los nuevos conjuntos obtenidos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsC95gDis4c7"
      },
      "source": [
        "poly = # COMPLETAR\n",
        "X_train_new = # COMPLETAR\n",
        "X_test_new = # COMPLETAR\n",
        "print(# COMPLETAR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8Kn-e2Ts4c7"
      },
      "source": [
        "4. Entrena una regresión lineal, observa los coeficientes obtenidos, y predice sobre el conjunto de Train y de Test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDx7dsNNuDpS"
      },
      "source": [
        "reg_2 = # COMPLETAR\n",
        "# COMPLETAR\n",
        "print(# COMPLETAR)\n",
        "y_train_pred_2 = # COMPLETAR\n",
        "y_test_pred_2 = # COMPLETAR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhR6P2Lms4c7"
      },
      "source": [
        "5. Calcula el error RMSE sobre cada conjunto, grafica la curva obtenida, el histograma de los errores y la relación $y$ vs. $y_{pred}$ como hicimos en los ejemplos anteriores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dx6ZZnRs4c7"
      },
      "source": [
        "# COMPLETAR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeHvMElsHlX0"
      },
      "source": [
        "### 3. Regularización\n",
        "\n",
        "Esperamos haberte convencido de que crear nuevos atributos funciona. Sin embargo, este ejemplo que te mostramos es demasiado sencillo por varios motivos:\n",
        "1. La relación entre los atributos y la variable a predecir es un polinomio de grado relativamente bajo. No solo eso, sino que además la conocemos.\n",
        "2. Solamente contamos con una sola variable predictora, `x`, cuando en realidad podrían ser más de un atributo. Como mencionamos en la bitácora, cuando agreguemos nuevos atributos, no solamente podemos considerar las potencias de cada atributo, sino también las interacciones - cosas de la forma $x_1 x_2$.\n",
        "\n",
        "No siempre sabremos hasta qué grado generar atributos ni si usar interraciones entre ellos. Es más, no siempre será un polinomio la relación entre $x$ e $y$, muchas veces directamente no tendremos claro qué tipo de relación es.\n",
        "\n",
        "Por suerte, los polinomios suelen ser una buena aproximación a otras funciones. Si no funciona, **podemos generar atributos que no sean polinómicos**, pero eso es algo que deberás investigar por tu cuenta si alguna vez lo necesitas. Por ahora, **es suficiente que sepas que los atributos polinómicos no son la única opción, pero suelen ser una opción versátil.**\n",
        "\n",
        "En lo que respecta al grado hasta el cual debemos agregar atributos, existe una técnica que nos permite controlar el error si nos pasamos un poco. Esta técnica se llama Regularización, y su alcance es mucho mayor que el aquí expuesto. Veamos cómo funciona.\n",
        "\n",
        "Vamos a usar de referencia el modelo que entrenaste en la sección anterior. Por las dudas, lo vamos a dejar entrenado nuevamente aquí. Es importante que prestes atención a los coeficientes de esta regresión lineal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B55gGkpqs4c7"
      },
      "source": [
        "poly = PolynomialFeatures(degree = 7, include_bias=False) ### ACA TENDRAS QUE MODIFICAR MAS ADELANTE\n",
        "X_train_new = poly.fit_transform(X_train)\n",
        "X_test_new = poly.transform(X_test)\n",
        "\n",
        "reg_2 = LinearRegression()\n",
        "reg_2.fit(X_train_new, y_train)\n",
        "\n",
        "evaluar_regresion(reg_2, x,y, X_train_new, X_test_new, y_train, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXNDoriyuSyd"
      },
      "source": [
        "Ahora, vamos a entrenar dos regresiones sobre el mismo dataset, pero con regularización. Esto lo puedes hacer con las clases `Ridge` y `Lasso` de Scikit-Learn. Como siempre, es prácticamente obligatorio que consultes su documentación.\n",
        "\n",
        "Empezamos entrenando el modelo `Ridge`. Presta atención a sus coeficientes:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiVHWZ6nKbhS"
      },
      "source": [
        "from sklearn.linear_model import Ridge, Lasso\n",
        "\n",
        "reg_ridge = Ridge(alpha= 0.1)\n",
        "reg_ridge.fit(X_train_new,y_train)\n",
        "\n",
        "print(f'Pendientes: {reg_ridge.coef_}')\n",
        "print(f'Ordenada: {reg_ridge.intercept_}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGv3_05As4c7"
      },
      "source": [
        "evaluar_regresion(reg_ridge, x,y, X_train_new, X_test_new, y_train, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOe7dpcKs4c7"
      },
      "source": [
        "**Para Probar:** modifica el valor de `alpha` y observa su efecto. ¿Cómo cambian los coeficientes? **Tip:** varía en órdenes de magnitud,  (10, 5, 1, 0.5, 0.1 ,0.01, 0.005, 0.001, etc.).\n",
        "\n",
        "Ahora, el modelo `Lasso`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYXA9b-Cs4c7"
      },
      "source": [
        "reg_lasso = Lasso(alpha = 0.001)\n",
        "reg_lasso.fit(X_train_new,y_train)\n",
        "print(reg_lasso.coef_, reg_lasso.intercept_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7mRwqTzs4c7"
      },
      "source": [
        "evaluar_regresion(reg_lasso, x,y, X_train_new, X_test_new, y_train, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zavqAoSzs4c7"
      },
      "source": [
        "**Para Probar:** nuevamente, modifica el valor de `alpha` y observa su efecto. ¿Cómo cambian los coeficientes?¿Notas alguna diferencia con el modelo `Ridge`? ¡Hay una diferencia importante, que hace que la regresión `Lasso` sea muy apreciada!\n",
        "\n",
        "**¿Qué pasa por fuera del rango de entrenamiento?**\n",
        "\n",
        "Estamos entrenando una regresión en un rango de $x$ entre -1 y 1. ¿Pero qué pasa si entrenamos en ese rango, y queremos ver cómo es la regresión por fuera? Es decir, para valores más grandes y más chicos que -1 y 1, respectivamente.\n",
        "\n",
        "Vamos a usar los modelos obtenidos para predecir por fuera de ese rango. Por las dudas, **reentrena los modelos `ridge` y `lasso` con valores de `alpha` razonables.** Si tuvieras que apostar, ¿cuál modelo te parece más robusto?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uekoAsY_s4c7"
      },
      "source": [
        "x_nuevo_rango = np.linspace(-2,2,1000)\n",
        "y_nuevo_rango = -1.5*x_nuevo_rango**4+3*x_nuevo_rango**2+1\n",
        "\n",
        "plt.plot(x_nuevo_rango, y_nuevo_rango, '--')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cW_kBmKDs4c7"
      },
      "source": [
        "X_nuevo_rango = poly.transform(x_nuevo_rango.reshape(-1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vx_Z4tKos4c7"
      },
      "source": [
        "plt.plot(x_nuevo_rango, y_nuevo_rango, '--', label = 'Curva Teorica')\n",
        "plt.plot(x_nuevo_rango, reg_2.predict(X_nuevo_rango), label = 'Regresión sin Regularización')\n",
        "plt.plot(x_nuevo_rango, reg_ridge.predict(X_nuevo_rango), label = 'Ridge')\n",
        "plt.plot(x_nuevo_rango, reg_lasso.predict(X_nuevo_rango), label = 'Lasso')\n",
        "plt.legend()\n",
        "\n",
        "### SI NO PUEDE VISUALIZAR CORRECTAMENTE, DESCOMENTA ESTAS LINEAS \n",
        "### Y PRUEBA DISTINTOS VALORES PARA LOS LIMITES\n",
        "# plt.xlim(-2.5,2.5)\n",
        "# plt.ylim(-10,10)\n",
        "\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IzviWt_s4c7"
      },
      "source": [
        "Tal vez el ejemplo por ahora no te parezca muy impresionante. De alguna forma, todos los modelos dan resultados muy parecidos. Pero recuerda lo siguiente: nosotros sabemos cómo es la relación funcional de los datos, un polinomio de grado 4. Cuando agregamos atributos, lo estamos haciendo hasta grado 7, lo cual no es mucho más grande que el grado original. \n",
        "\n",
        "**Para Probar:** Para ver el verdadero efecto de la regularización, agrega atributos polinómicos hasta un grado alto, por ejemplo 50, 100, 150 ó más. Vuelve a correr la regresión sin regularización, y la regresión Ridge y Lasso, y fíjate qué sucede. Tal vez puedes volver a probar con algunos valores nuevos de `alpha`.\n",
        "\n",
        "\n",
        "## Conclusiones\n",
        "\n",
        "Es posible ajustar relaciones no-lineales con un modelo lineal, pero tiene un costo: agregar nuevos atributos. Esto no solo hace crecer de manera considerable nuestro dataset, sino que además introduce un nuevo hiperparámetro, el grado hasta el cual agregamos atributos. Esto se soluciona parcialmente con regularización, pero a costa de otro hiperparámetro, la fuerza de la regularización, $\\alpha$. Para colmo, estos hiperparámetros que acabamos de mencionar de alguna forma interactuan: a más atributos agreguemos, $\\alpha$ probablemente deba tomar otro valor.\n",
        "\n",
        "Como si esto no fuera poco, hay que tener mucho cuidado cuando usamos un modelo de regresión entrenado en un rango para predecir por fuera de ese rango. Como verás, las cosas pueden andar muy mal. Por suerte, esto no es un problema en muchas aplicaciones, pero es algo a lo que debes estar atento/a.\n",
        "\n",
        "\n",
        "## 4. Ejercitación\n",
        "\n",
        "Si todavía no estás muy cansado/a, puedes intentar hacer algunos de - o todos - los siguientes ejercicios:\n",
        "1. Experimenta con alguna técnica para visualizar los coeficientes de una regresión, de forma tal de poder observar los efectos de la regularización en ellos.\n",
        "1. Puedes aplicar lo que vimos hoy en cualquiera de los dos datasets que te dejamos para descargar en la bitácora. Son datasets sintéticos, pero te servirán como práctica más realista de estas herramientas.\n",
        "1. ¿Recuerdas el Proyecto del Bloque 01? ¡Aplica lo aprendido en ese dataset!"
      ]
    }
  ]
}